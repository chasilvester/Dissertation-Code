{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Zygote\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using LinearAlgebra\n",
    "using MathOptInterface\n",
    "const MOI = MathOptInterface\n",
    "using SparseArrays\n",
    "using BenchmarkTools\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feasibility restoration phase function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function restoration_phase(xk, ρ)\n",
    "    println(\"Solving restoration problem\")\n",
    "    \n",
    "    is_s_eq_0 = false\n",
    "    \n",
    "    # Define nonlinear model in JuMP\n",
    "    nlrp = Model()\n",
    "    set_silent(nlrp)\n",
    "    @variable(nlrp, x[i=1:2])\n",
    "    @NLobjective(nlrp, Min, (x[1] - 2)^2 + (x[2] - 2)^2)\n",
    "    @NLconstraint(nlrp, c, x[1]^2 + x[2]^2 - 1 <= 0)\n",
    "    \n",
    "    # Initialise MOI evaluator\n",
    "    pp = NLPEvaluator(nlrp)\n",
    "    MOI.initialize(pp, [:Jac,:Grad,:Hess])\n",
    "\n",
    "    # Iterate until convergence\n",
    "    while !is_s_eq_0\n",
    "        \n",
    "        #Constraint eval\n",
    "        ggg=zeros(1)\n",
    "        MOI.eval_constraint(pp,ggg,xk)\n",
    "\n",
    "        #Jacobian eval\n",
    "        JStru=MOI.jacobian_structure(pp)\n",
    "        Ja=zeros(length(JStru))\n",
    "        MOI.eval_constraint_jacobian(pp,Ja,xk)\n",
    "\n",
    "        jr = Vector{Int64}(undef, length(Ja)); jc = Vector{Int64}(undef, length(Ja))\n",
    "        for i in 1:length(JStru)\n",
    "            jr[i] = JStru[i][1] |> Int\n",
    "            jc[i] = JStru[i][2] |> Int\n",
    "        end\n",
    "        Jacobeval = sparse(jr, jc, Ja) \n",
    "        @assert size(Jacobeval, 1) == 1\n",
    "                                        \n",
    "        Jacobeval = vcat(Jacobeval...)\n",
    "        \n",
    "        # Linearised restoration phase model\n",
    "        restor_model = Model(Ipopt.Optimizer)\n",
    "        set_silent(restor_model)\n",
    "        @variable(restor_model, s >= 0)\n",
    "        @variable(restor_model, d[i=1:2])\n",
    "\n",
    "        @objective(restor_model, Min, s) \n",
    "        @constraint(restor_model, c1, ggg[1] + Jacobeval'*d - s <= 0)\n",
    "        @constraint(restor_model, c2, d[1] <= ρ)\n",
    "        @constraint(restor_model, c3, d[2] <= ρ) \n",
    "        @constraint(restor_model, c4, d[1] >= -ρ)\n",
    "        @constraint(restor_model, c5, d[2] >= -ρ)\n",
    "        optimize!(restor_model)\n",
    "\n",
    "        proposed_xk = xk .+ value.(d)\n",
    "        \n",
    "        # merit function\n",
    "        function m(x::Vector{<:Real}) \n",
    "            ce = zeros(1)\n",
    "            MOI.eval_constraint(pp,ce,x)\n",
    "            merit = norm(max(ce[1], 0))\n",
    "            return merit\n",
    "        end\n",
    "\n",
    "        if abs(value(s)) < 1e-6\n",
    "        elseif m(proposed_xk) < m(xk) \n",
    "            println(\"restoration merit condition: success\")\n",
    "            xk = proposed_xk\n",
    "            ρ += 1*ρ\n",
    "        else\n",
    "            println(\"restoration merit condition: failed\")\n",
    "            ρ -= 0.5*ρ\n",
    "        end\n",
    "        \n",
    "        println(\"slack = $(value(s))\")\n",
    "        is_s_eq_0 = abs(value(s)) < 1e-6\n",
    "    end\n",
    "    \n",
    "    return xk, ρ \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLP with a merit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SLP_MF(xk::Vector{<:Real}, ρ, γ)\n",
    "    # ρ and γ are parameters\n",
    "    @assert γ>=0\n",
    "    \n",
    "    has_x_converged = false\n",
    "    ctr = 0\n",
    "    restor_ctr = 0\n",
    "\n",
    "    # Nonlinear model in JuMP\n",
    "    nlmod = Model()\n",
    "    set_silent(nlmod)\n",
    "    @variable(nlmod, x[i=1:2])\n",
    "    @NLobjective(nlmod, Min, (x[1] - 2)^2 + (x[2] - 2)^2)\n",
    "    @NLconstraint(nlmod, c, x[1]^2 + x[2]^2 - 1 <= 0)\n",
    "    \n",
    "    # Initialise MOI evaluator\n",
    "    p = NLPEvaluator(nlmod)\n",
    "    MOI.initialize(p, [:Jac,:Grad,:Hess])\n",
    "    \n",
    "\n",
    "    while has_x_converged != [1, 1]\n",
    "        ctr += 1\n",
    "        \n",
    "        #Objective eval\n",
    "        objEv=MOI.eval_objective(p, xk)\n",
    "\n",
    "        #Objective gradient\n",
    "        df=zeros(length(xk))\n",
    "        MOI.eval_objective_gradient(p,df,xk)\n",
    "\n",
    "        #Constraint eval\n",
    "        gg=zeros(1)\n",
    "        MOI.eval_constraint(p,gg,xk)\n",
    "\n",
    "        #Jacobian eval\n",
    "        JStr=MOI.jacobian_structure(p)\n",
    "        J=zeros(length(JStr))\n",
    "        MOI.eval_constraint_jacobian(p,J,xk)\n",
    "\n",
    "        jr = Vector{Int64}(undef, length(J)); jc = Vector{Int64}(undef, length(J))\n",
    "        for i in 1:length(JStr)\n",
    "            jr[i] = JStr[i][1] |> Int\n",
    "            jc[i] = JStr[i][2] |> Int\n",
    "        end\n",
    "        Jacobeval = sparse(jr, jc, J) \n",
    "        @assert size(Jacobeval, 1) == 1                              \n",
    "        Jacobeval = vcat(Jacobeval...)\n",
    "\n",
    "        # Define linearised model in JuMP\n",
    "        model = Model(Ipopt.Optimizer)\n",
    "        set_silent(model)\n",
    "        @variable(model, d[i=1:2])\n",
    "        @objective(model, Min, objEv + df'*d)\n",
    "        @constraint(model, c1,  gg[1] + Jacobeval'*d <= 0)\n",
    "        @constraint(model, c2, d[1] <= ρ)\n",
    "        @constraint(model, c3, d[2] <= ρ) \n",
    "        @constraint(model, c4, d[1] >= -ρ)\n",
    "        @constraint(model, c5, d[2] >= -ρ)\n",
    "        \n",
    "        println(\"Iteration $ctr...\")\n",
    "\n",
    "        optimize!(model)\n",
    "        @show termination_status(model)\n",
    "        \n",
    "        # update step\n",
    "        proposed_xk = xk .+ value.(d)\n",
    "        \n",
    "        # merit function\n",
    "        function m(x::Vector{<:Real}) \n",
    "            newobjev = MOI.eval_objective(p, x)\n",
    "            ce = zeros(1)\n",
    "            MOI.eval_constraint(p,ce,x)\n",
    "            merit = newobjev + γ * norm(max(ce[1], 0))\n",
    "            return merit\n",
    "        end\n",
    "        \n",
    "        println(\"m(xk) = $(m(xk))\")\n",
    "        println(\"m(prop_xk) = $(m(proposed_xk))\")\n",
    "        \n",
    "        if m(proposed_xk) < m(xk)\n",
    "            println(\"merit condition: success\")\n",
    "            xk = proposed_xk\n",
    "            ρ += 1*ρ\n",
    "        else\n",
    "            println(\"merit condition: failed\")\n",
    "            ρ -= 0.5*ρ\n",
    "        end\n",
    "        \n",
    "        println(\"d=$(value.(d))\")\n",
    "        println(\"x$(ctr)=$(xk)\")\n",
    "        \n",
    "        # restoration phase:\n",
    "        if termination_status(model) == MathOptInterface.LOCALLY_INFEASIBLE\n",
    "            xk, ρ = restoration_phase(xk, ρ)\n",
    "            restor_ctr += 1\n",
    "        end\n",
    "        \n",
    "        #convergence test\n",
    "        tol = 1e-6\n",
    "        has_x_converged = abs.(value.(d)) .< tol\n",
    "        \n",
    "    end\n",
    "    println(\"no. restoration phases: $(restor_ctr)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLP_MF([2., 2.], 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLP with a filter function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SLP_F(xk::Vector{<:Real}, ρ)\n",
    "    # ρ is the trust region parameter\n",
    "\n",
    "    has_x_converged = false\n",
    "    ctr = 0\n",
    "    restor_ctr = 0\n",
    "    \n",
    "    filt = []\n",
    "    \n",
    "    # Define nonlinear model in JuMP\n",
    "    nlmod = Model()\n",
    "    set_silent(nlmod)\n",
    "    @variable(nlmod, x[i=1:2])\n",
    "    @NLobjective(nlmod, Min, (x[1] - 2)^2 + (x[2] - 2)^2)\n",
    "    @NLconstraint(nlmod, c, x[1]^2 + x[2]^2 - 1 <= 0)\n",
    "    \n",
    "    # Initialise MOI evaluator\n",
    "    p = NLPEvaluator(nlmod)\n",
    "    MOI.initialize(p, [:Jac,:Grad,:Hess])\n",
    "    \n",
    "    while has_x_converged != [1, 1]\n",
    "        ctr += 1\n",
    "        \n",
    "        #Objective eval\n",
    "        objEv=MOI.eval_objective(p, xk)\n",
    "\n",
    "        #Objective gradient\n",
    "        df=zeros(length(xk))\n",
    "        MOI.eval_objective_gradient(p,df,xk)\n",
    "\n",
    "        #Constraint eval\n",
    "        gg=zeros(1)\n",
    "        MOI.eval_constraint(p,gg,xk)\n",
    "\n",
    "        #Jacobian eval\n",
    "        JStr=MOI.jacobian_structure(p)\n",
    "        J=zeros(length(JStr))\n",
    "        MOI.eval_constraint_jacobian(p,J,xk)\n",
    "\n",
    "        jr = Vector{Int64}(undef, length(J)); jc = Vector{Int64}(undef, length(J))\n",
    "        for i in 1:length(JStr)\n",
    "            jr[i] = JStr[i][1] |> Int\n",
    "            jc[i] = JStr[i][2] |> Int\n",
    "        end\n",
    "        Jacobeval = sparse(jr, jc, J) \n",
    "        @assert size(Jacobeval, 1) == 1                              \n",
    "        Jacobeval = vcat(Jacobeval...)\n",
    "        \n",
    "        # Define linearised model in JuMP\n",
    "        model = Model(Ipopt.Optimizer)\n",
    "        set_silent(model)\n",
    "        @variable(model, d[i=1:2])\n",
    "\n",
    "        println(\"Iteration $ctr...\")\n",
    "\n",
    "        @objective(model, Min, objEv + df'*d) \n",
    "        @constraint(model, c1, gg[1] + Jacobeval'*d <= 0)\n",
    "        @constraint(model, c2, d[1] <= ρ)\n",
    "        @constraint(model, c3, d[2] <= ρ)\n",
    "        @constraint(model, c4, d[1] >= -ρ)\n",
    "        @constraint(model, c5, d[2] >= -ρ)\n",
    "\n",
    "        optimize!(model)\n",
    "        \n",
    "        #functions for making the filter\n",
    "        function fk(x::Vector{<:Real}) \n",
    "            newobjev = MOI.eval_objective(p, x)\n",
    "            return newobjev\n",
    "        end\n",
    "        function hk(x::Vector{<:Real}) \n",
    "            ce = zeros(1)\n",
    "            MOI.eval_constraint(p,ce,x)\n",
    "            h = norm(max(ce[1], 0))\n",
    "            return h\n",
    "        end\n",
    "        \n",
    "        proposed_xk = xk .+ value.(d)\n",
    "        better_obj = all(v -> fk(proposed_xk) < v[1], filt)\n",
    "        better_constr = all(v -> hk(proposed_xk) < v[2], filt)\n",
    "        \n",
    "        if better_obj || better_constr\n",
    "            println(\"filter: accept\")\n",
    "            xk = proposed_xk\n",
    "            ρ += 1*ρ\n",
    "            filt = push!(filt, (fk(xk), hk(xk)))\n",
    "        else\n",
    "            println(\"filter: reject\")\n",
    "            ρ -= 0.5*ρ\n",
    "            filt = push!(filt, (fk(proposed_xk), hk(proposed_xk)))\n",
    "        end\n",
    "        \n",
    "        \n",
    "        println(\"f(propxk) = $(fk(proposed_xk))\")\n",
    "        println(\"d=$(value.(d))\")\n",
    "        println(\"x$(ctr)=$xk\")  \n",
    "        \n",
    "        #restoration phase:\n",
    "        if termination_status(model) == MathOptInterface.LOCALLY_INFEASIBLE\n",
    "            xk, ρ = restoration_phase(xk, ρ)\n",
    "            restor_ctr += 1\n",
    "        end\n",
    "    \n",
    "        #convergence test\n",
    "        tol = 1e-6\n",
    "        has_x_converged = abs.(value.(d)) .< tol\n",
    "    end\n",
    "    println(\"no. restoration phases: $(restor_ctr)\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLP_F([100., -100.], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQP with a merit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SQP_MF(xk::Vector{<:Real}, λk::Vector{Float64}, ρ, γ)\n",
    "    # λ, μ are initial lagrangian multipliers\n",
    "    # ρ and γ are parameters\n",
    "\n",
    "    has_x_converged = false\n",
    "    ctr = 0\n",
    "    restor_ctr = 0\n",
    "    \n",
    "    # Nonlinear model\n",
    "    mhl = Model(Ipopt.Optimizer)\n",
    "    @variable(mhl, x[i=1:2])\n",
    "    @NLobjective(mhl, Min, (x[1] - 2)^2 + (x[2] - 2)^2 )\n",
    "    @NLconstraint(mhl, c, x[1]^2 + x[2]^2 - 1 <= 0)\n",
    "    p = NLPEvaluator(mhl)\n",
    "    MOI.initialize(p, [:Jac,:Grad,:Hess])\n",
    "    \n",
    "    while has_x_converged != [1, 1]\n",
    "        ctr += 1\n",
    "        \n",
    "        #Objective eval\n",
    "        objEv=MOI.eval_objective(p, xk)\n",
    "\n",
    "        #Objective gradient\n",
    "        df=zeros(length(xk))\n",
    "        MOI.eval_objective_gradient(p,df,xk)\n",
    "\n",
    "        #Constraint eval\n",
    "        gg=zeros(1)\n",
    "        MOI.eval_constraint(p,gg,xk)\n",
    "\n",
    "        #Jacobian eval\n",
    "        JStr=MOI.jacobian_structure(p)\n",
    "        J=zeros(length(JStr))\n",
    "        MOI.eval_constraint_jacobian(p,J,xk)\n",
    "\n",
    "        jr = Vector{Int64}(undef, length(J)); jc = Vector{Int64}(undef, length(J))\n",
    "        for i in 1:length(JStr)\n",
    "            jr[i] = JStr[i][1] |> Int\n",
    "            jc[i] = JStr[i][2] |> Int\n",
    "        end\n",
    "        Jacobeval = sparse(jr, jc, J) \n",
    "        @assert size(Jacobeval, 1) == 1                              \n",
    "        Jacobeval = vcat(Jacobeval...)\n",
    "        \n",
    "        #Hessian-of-the-Lagrangian eval\n",
    "        HStr=MOI.hessian_lagrangian_structure(p)\n",
    "        H=zeros(length(HStr))\n",
    "        MOI.eval_hessian_lagrangian(p,H,xk,1.0,repeat(λk,length(H))) # instead of repeat have lagrange multipliers\n",
    "        \n",
    "        hr = Vector{Int64}(undef, length(H)); hc = Vector{Int64}(undef, length(H))\n",
    "        for i in 1:length(HStr)\n",
    "            hr[i] = HStr[i][1] |> Int\n",
    "            hc[i] = HStr[i][2] |> Int\n",
    "        end\n",
    "        \n",
    "        HessLag = sparse(hr, hc, H)\n",
    "        \n",
    "        hessianobj(d) = 0.5*d'*(HessLag*d)\n",
    "        \n",
    "        # Linearised model\n",
    "        model = Model(Ipopt.Optimizer)\n",
    "        set_silent(model)\n",
    "        @variable(model, d[i=1:2])\n",
    "        @objective(model, Min, objEv + df'*d + hessianobj(d)) \n",
    "        @constraint(model, c1, gg[1] + Jacobeval'*d <= 0)\n",
    "        @constraint(model, c2, d[1] <= ρ)\n",
    "        @constraint(model, c3, d[2] <= ρ)\n",
    "        @constraint(model, c4, d[1] >= -ρ)\n",
    "        @constraint(model, c5, d[2] >= -ρ)\n",
    "        \n",
    "        println(\"Iteration $ctr...\")\n",
    "\n",
    "        optimize!(model)\n",
    "        @show termination_status(model)\n",
    "        \n",
    "        # update λ\n",
    "        λk[1] = shadow_price(c1)\n",
    "        println(\"lambda$(ctr) = $(λk[1])\")\n",
    "\n",
    "        # merit function\n",
    "        function m(x::Vector{<:Real}) \n",
    "            newobjev = MOI.eval_objective(p, x)\n",
    "            ce = zeros(1)\n",
    "            MOI.eval_constraint(p,ce,x)\n",
    "            merit = newobjev + γ * norm(max(ce[1], 0))\n",
    "            return merit\n",
    "        end\n",
    "        \n",
    "        # updating ρ\n",
    "        proposed_xk = xk .+ value.(d)\n",
    "        \n",
    "        println(\"m(prop_xk) = $(m(proposed_xk))\")\n",
    "        println(\"m(xk) = $(m(xk))\")\n",
    "        \n",
    "        if m(proposed_xk) < m(xk)\n",
    "            println(\"merit condition: success\")\n",
    "            xk = proposed_xk\n",
    "            ρ += 1*ρ\n",
    "        else\n",
    "            println(\"merit condition: failed\")\n",
    "            ρ -= 0.5*ρ\n",
    "        end\n",
    "        \n",
    "        println(\"d=$(value.(d))\")\n",
    "        println(\"x$ctr=$xk\")\n",
    "        \n",
    "        #restoration phase:\n",
    "        if termination_status(model) == MathOptInterface.LOCALLY_INFEASIBLE\n",
    "            xk, ρ = restoration_phase(xk, ρ)\n",
    "            restor_ctr += 1\n",
    "        end\n",
    "        \n",
    "        #convergence test\n",
    "        tol = 1e-6\n",
    "        has_x_converged = abs.(value.(d)) .< tol\n",
    "    end\n",
    "    println(\"no. restoration phases: $(restor_ctr)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQP_MF([2., 2.], [1.], 4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQP with a filter function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SQP_F(xk::Vector{<:Real}, λk::Vector{Float64}, ρ)\n",
    "    # λ is initial lagrangian multiplier\n",
    "    # ρ is the trust region parameter\n",
    "\n",
    "    has_x_converged = false\n",
    "    ctr = 0\n",
    "    restor_ctr = 0\n",
    "    \n",
    "    filt = []\n",
    "    \n",
    "    # Nonlinear model\n",
    "    mhl = Model(Ipopt.Optimizer)\n",
    "    @variable(mhl, x[i=1:2])\n",
    "    @NLobjective(mhl, Min, (x[1] - 2)^2 + (x[2] - 2)^2 )\n",
    "    @NLconstraint(mhl, c1, x[1]^2 + x[2]^2 - 1 <= 0)\n",
    "    p = NLPEvaluator(mhl)\n",
    "    MOI.initialize(p, [:Jac,:Grad,:Hess])\n",
    "    \n",
    "    while has_x_converged != [1, 1]\n",
    "        ctr += 1\n",
    "        \n",
    "        #Objective eval\n",
    "        objEv=MOI.eval_objective(p, xk)\n",
    "\n",
    "        #Objective gradient\n",
    "        df=zeros(length(xk))\n",
    "        MOI.eval_objective_gradient(p,df,xk)\n",
    "\n",
    "        #Constraint eval\n",
    "        gg=zeros(1)\n",
    "        MOI.eval_constraint(p,gg,xk)\n",
    "\n",
    "        #Jacobian eval\n",
    "        JStr=MOI.jacobian_structure(p)\n",
    "        J=zeros(length(JStr))\n",
    "        MOI.eval_constraint_jacobian(p,J,xk)\n",
    "\n",
    "        jr = Vector{Int64}(undef, length(J)); jc = Vector{Int64}(undef, length(J))\n",
    "        for i in 1:length(JStr)\n",
    "            jr[i] = JStr[i][1] |> Int\n",
    "            jc[i] = JStr[i][2] |> Int\n",
    "        end\n",
    "        Jacobeval = sparse(jr, jc, J) \n",
    "        @assert size(Jacobeval, 1) == 1                              \n",
    "        Jacobeval = vcat(Jacobeval...)\n",
    "        \n",
    "        #Hessian-of-the-Lagrangian eval\n",
    "        HStr=MOI.hessian_lagrangian_structure(p)\n",
    "        H=zeros(length(HStr))\n",
    "        MOI.eval_hessian_lagrangian(p,H,xk,1.0,repeat(λk,length(H))) \n",
    "        \n",
    "        hr = Vector{Int64}(undef, length(H)); hc = Vector{Int64}(undef, length(H))\n",
    "        for i in 1:length(HStr)\n",
    "            hr[i] = HStr[i][1] |> Int\n",
    "            hc[i] = HStr[i][2] |> Int\n",
    "        end\n",
    "        HessLag = sparse(hr, hc, H)\n",
    "        \n",
    "        hessianobj(d) = 0.5*d'*(HessLag*d)\n",
    "        \n",
    "        model = Model(Ipopt.Optimizer)\n",
    "        set_silent(model)\n",
    "        @variable(model, d[i=1:2])\n",
    "        @objective(model, Min, objEv + df'*d + hessianobj(d)) \n",
    "        @constraint(model, c1, gg[1] + Jacobeval'*d <= 0)\n",
    "        @constraint(model, c2, d[1] <= ρ)\n",
    "        @constraint(model, c3, d[2] <= ρ)\n",
    "        @constraint(model, c4, d[1] >= -ρ)\n",
    "        @constraint(model, c5, d[2] >= -ρ)\n",
    "\n",
    "                \n",
    "        println(\"Iteration $ctr...\")\n",
    "     \n",
    "        optimize!(model)\n",
    "        \n",
    "        # Update λ\n",
    "        λk[1] = shadow_price(c1)\n",
    "\n",
    "        # Functions for making the filter\n",
    "        function fk(x::Vector{<:Real}) \n",
    "            newobjev = MOI.eval_objective(p, x)\n",
    "            return newobjev\n",
    "        end\n",
    "        function hk(x::Vector{<:Real}) \n",
    "            ce = zeros(1)\n",
    "            MOI.eval_constraint(p,ce,x)\n",
    "            h = norm(max(ce[1], 0))\n",
    "            return h\n",
    "        end\n",
    "        \n",
    "        # Update step\n",
    "        proposed_xk = xk .+ value.(d)\n",
    "        better_obj = all(v -> fk(proposed_xk) < v[1], filt)\n",
    "        better_constr = all(v -> hk(proposed_xk) < v[2], filt)\n",
    "        \n",
    "        if better_obj || better_constr\n",
    "            println(\"filter: accept\")\n",
    "            xk = proposed_xk\n",
    "            ρ += 1*ρ\n",
    "            filter = push!(filt, (fk(xk), hk(xk)))\n",
    "        else\n",
    "            println(\"filter: reject\")\n",
    "            ρ -= 0.5*ρ\n",
    "            filter = push!(filt, (fk(proposed_xk), hk(proposed_xk)))\n",
    "        end\n",
    "        \n",
    "        println(\"f(propxk) = $(fk(proposed_xk))\")\n",
    "        println(\"d=$(value.(d))\")\n",
    "        println(\"x$ctr=$xk\")\n",
    "        \n",
    "        #restoration phase:\n",
    "        if termination_status(model) == MathOptInterface.LOCALLY_INFEASIBLE\n",
    "            xk, ρ = restoration_phase(xk, ρ)\n",
    "            restor_ctr += 1\n",
    "        end\n",
    "        \n",
    "        #convergence test\n",
    "        tol = 1e-6\n",
    "        has_x_converged = abs.(value.(d)) .< tol\n",
    "    end\n",
    "    println(\"no. restoration phases: $(restor_ctr)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQP_F([100., -100.], [1.], 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
